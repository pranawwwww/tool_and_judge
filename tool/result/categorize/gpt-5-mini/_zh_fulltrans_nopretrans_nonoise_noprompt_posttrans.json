{"id": "multiple_3", "category": "relevant_but_incorrect", "evaluation_entry": {"id": "multiple_3", "valid": false, "error": "invalid_param_value", "error_meta": {"param": "rounding", "actual_value": 3, "expected_values": ["", 0], "decoded_output": [{"EuclideanDistance.calculate": {"rounding": 3, "pointA": [3, 4], "pointB": [1, 2]}}], "possible_answer": {"EuclideanDistance.calculate": {"pointA": [[3, 4]], "pointB": [[1, 2]], "rounding": ["", 0]}}}}}
{"id": "multiple_7", "category": "misc_errors", "evaluation_entry": {"id": "multiple_7", "valid": false, "error": "invalid_entry_count", "error_meta": {"entry_count": 2, "decoded_output": [{"wildlife_population.assess_growth": {"duration": 10, "species": "deer (Odocoileus spp.)", "location": "Washington, USA"}}, {"ecological_impact.analyze": {"timeframe": 10, "species": "deer (Odocoileus spp.)", "ecosystem": "forest ecosystems (mixed conifer and deciduous forests)", "location": "Washington, USA"}}], "possible_answer": [{"wildlife_population.assess_growth": {"species": ["deer", "Deer"], "location": ["Washington state", "WA", "Washington"], "duration": [10]}}]}}}
{"id": "multiple_9", "category": "misc_errors", "evaluation_entry": {"id": "multiple_9", "valid": false, "error": "missing_required_param", "error_meta": {"missing_param": "gradeDict", "required_params": ["gradeDict"], "decoded_output": [{"calculate_average": {}}], "possible_answer": {"calculate_average": {"gradeDict": [{"math": [90], "science": [75], "history": [82], "music": [89]}]}}}}}
{"id": "multiple_10", "category": "misc_errors", "evaluation_entry": {"id": "multiple_10", "valid": false, "error": "invalid_entry_count", "error_meta": {"entry_count": 2, "decoded_output": [{"database.create_backup": {"timestamp": true, "db_name": "employee", "backup_location": "/backups/employee_personal_data_backup.bak"}}, {"database.modify_columns": {"db_name": "employee", "table": "personal_data", "operation": "delete", "columns": ["email", "ssn"]}}], "possible_answer": [{"database.modify_columns": {"db_name": ["employees"], "table": ["personal_data"], "operation": ["delete"], "columns": [["email", "ssn"], ["ssn", "email"], ["email", "social_security_number"], ["social_security_number", "email"], ["email", "social security number"], ["social security number", "email"]]}}]}}}
{"id": "multiple_13", "category": "misc_errors", "evaluation_entry": {"id": "multiple_13", "valid": false, "error": "invalid_entry_count", "error_meta": {"entry_count": 2, "decoded_output": [{"corporate_finance.product_price": {"company": "XYZ", "product": "Product A"}}, {"corporate_finance.revenue_forecast": {"sales_units_increase_percentage": 10, "company": "XYZ", "product": "Product A"}}], "possible_answer": [{"corporate_finance.revenue_forecast": {"company": ["XYZ"], "product": ["A", "Product A"], "sales_units_increase_percentage": [10]}}]}}}
{"id": "multiple_16", "category": "exactly_same_meaning", "evaluation_entry": {"id": "multiple_16", "valid": false, "error": "invalid_param_value", "error_meta": {"param": "species", "actual_value": "Wild tiger (Panthera tigris)", "expected_values": ["wild tiger", "tiger"], "decoded_output": [{"population_genetics.calculate_ne": {"generations": 100, "probability": 0.95, "species": "Wild tiger (Panthera tigris)"}}], "possible_answer": {"population_genetics.calculate_ne": {"species": ["wild tiger", "tiger"], "generations": [100], "probability": [0.95]}}}}}
{"id": "multiple_23", "category": "relevant_but_incorrect", "evaluation_entry": {"id": "multiple_23", "valid": false, "error": "invalid_param_value", "error_meta": {"param": "stats_fields", "actual_value": ["points", "assists", "rebounds", "minutes"], "expected_values": [["points per game", "assists", "minutes per game"], ["points per game", "minutes per game", "assists"], ["assists", "points per game", "minutes per game"], ["assists", "minutes per game", "points per game"], ["minutes per game", "points per game", "assists"], ["minutes per game", "assists", "points per game"], ["points", "assists", "minutes"], ["points", "minutes", "assists"], ["assists", "points", "minutes"], ["assists", "minutes", "points"], ["minutes", "points", "assists"], ["minutes", "assists", "points"], ["points_per_game", "assists", "minutes_per_game"], ["points_per_game", "minutes_per_game", "assists"], ["assists", "points_per_game", "minutes_per_game"], ["assists", "minutes_per_game", "points_per_game"], ["minutes_per_game", "points_per_game", "assists"], ["minutes_per_game", "assists", "points_per_game"]], "decoded_output": [{"basketball.player_stats.get": {"player_name": "LeBron James", "stats_fields": ["points", "assists", "rebounds", "minutes"]}}], "possible_answer": {"basketball.player_stats.get": {"player_name": ["LeBron James"], "stats_fields": [["points per game", "assists", "minutes per game"], ["points per game", "minutes per game", "assists"], ["assists", "points per game", "minutes per game"], ["assists", "minutes per game", "points per game"], ["minutes per game", "points per game", "assists"], ["minutes per game", "assists", "points per game"], ["points", "assists", "minutes"], ["points", "minutes", "assists"], ["assists", "points", "minutes"], ["assists", "minutes", "points"], ["minutes", "points", "assists"], ["minutes", "assists", "points"], ["points_per_game", "assists", "minutes_per_game"], ["points_per_game", "minutes_per_game", "assists"], ["assists", "points_per_game", "minutes_per_game"], ["assists", "minutes_per_game", "points_per_game"], ["minutes_per_game", "points_per_game", "assists"], ["minutes_per_game", "assists", "points_per_game"]]}}}}}
{"id": "multiple_25", "category": "exactly_same_meaning", "evaluation_entry": {"id": "multiple_25", "valid": false, "error": "invalid_param_value", "error_meta": {"param": "game_title", "actual_value": "Assassin's Creed Valhalla", "expected_values": ["Assassins Creed Valhalla"], "decoded_output": [{"video_games.store_price": {"game_title": "Assassin's Creed Valhalla", "platform": "PlayStation", "region": "United States"}}], "possible_answer": {"video_games.store_price": {"game_title": ["Assassins Creed Valhalla"], "platform": ["PlayStation", "PS"], "region": ["United States", "US", ""]}}}}}
{"id": "multiple_29", "category": "exactly_same_meaning", "evaluation_entry": {"id": "multiple_29", "valid": false, "error": "invalid_param_value", "error_meta": {"param": "function1", "actual_value": "3x+2", "expected_values": ["3x + 2", "lambda x: 3x + 2"], "decoded_output": [{"functions.intersect": {"function1": "3x+2", "function2": "2x+3"}}], "possible_answer": {"functions.intersect": {"function1": ["3x + 2", "lambda x: 3x + 2"], "function2": ["2x + 3", "lambda x: 2x + 3"]}}}}}
{"id": "multiple_32", "category": "relevant_but_incorrect", "evaluation_entry": {"id": "multiple_32", "valid": false, "error": "invalid_param_value", "error_meta": {"param": "round_off", "actual_value": 4, "expected_values": ["", 0], "decoded_output": [{"geometry.calculate_cone_volume": {"radius": 4, "height": 7, "round_off": 4}}], "possible_answer": {"geometry.calculate_cone_volume": {"radius": [4], "height": [7], "round_off": ["", 0]}}}}}
{"id": "multiple_33", "category": "relevant_but_incorrect", "evaluation_entry": {"id": "multiple_33", "valid": false, "error": "invalid_param_value", "error_meta": {"param": "func", "actual_value": "3*x^2", "expected_values": ["3x**2", "lambda x: 3x**2"], "decoded_output": [{"calculate_integral": {"a": 1, "b": 2, "func": "3*x^2"}}], "possible_answer": {"calculate_integral": {"func": ["3x**2", "lambda x: 3x**2"], "a": [1], "b": [2]}}}}}
{"id": "multiple_38", "category": "relevant_but_incorrect", "evaluation_entry": {"id": "multiple_38", "valid": false, "error": "invalid_param_value", "error_meta": {"param": "availability", "actual_value": true, "expected_values": ["", false], "decoded_output": [{"library.search_book": {"availability": true, "genre": "", "book_name": "The Shepherd Boy's Magical Journey", "city": "New York City"}}], "possible_answer": {"library.search_book": {"book_name": ["The Alchemist"], "city": ["New York", "New York, NY", "New York City", "NYC", "NY"], "availability": ["", false], "genre": [""]}}}}}
{"id": "multiple_45", "category": "exactly_same_meaning", "evaluation_entry": {"id": "multiple_45", "valid": false, "error": "invalid_param_value", "error_meta": {"param": "era_name", "actual_value": "Ice Age", "expected_values": ["Ice age"], "decoded_output": [{"geology.get_era": {"calculate_years_ago": true, "era_name": "Ice Age"}}], "possible_answer": {"geology.get_era": {"era_name": ["Ice age"], "calculate_years_ago": [true]}}}}}
{"id": "multiple_47", "category": "wrong_values", "evaluation_entry": {"id": "multiple_47", "valid": false, "error": "invalid_param_value", "error_meta": {"param": "rounding", "actual_value": 6, "expected_values": ["", 0], "decoded_output": [{"cosine_similarity.calculate": {"rounding": 6, "vector1": [3, 2, 1], "vector2": [1, 2, 3]}}], "possible_answer": {"cosine_similarity.calculate": {"vector1": [[3, 2, 1]], "vector2": [[1, 2, 3]], "rounding": ["", 0]}}}}}
{"id": "multiple_50", "category": "wrong_values", "evaluation_entry": {"id": "multiple_50", "valid": false, "error": "invalid_param_value", "error_meta": {"param": "features", "actual_value": ["SqFt", "Bedrooms", "Bathrooms", "Location"], "expected_values": [[], ""], "decoded_output": [{"house_price_forecast": {"months": 1, "location": "New York, NY", "features": ["SqFt", "Bedrooms", "Bathrooms", "Location"]}}], "possible_answer": {"house_price_forecast": {"location": ["New York", "New York, NY", "NYC", "New York City"], "months": [1], "features": [[], ""]}}}}}
{"id": "multiple_53", "category": "misc_errors", "evaluation_entry": {"id": "multiple_53", "valid": false, "error": "invalid_entry_count", "error_meta": {"entry_count": 2, "decoded_output": [{"linear_regression": {"forecast_period": 5, "dependent_var": "house_price", "independent_var": ["interest_rate", "unemployment rate"]}}, {"random_forest_regression": {"n_estimators": 100, "forecast_period": 5, "dependent_var": "house_price", "independent_var": ["interest_rate", "unemployment_rate"]}}], "possible_answer": [{"linear_regression": {"independent_var": [["interest rates", "unemployment rates"], ["interest_rate", "unemployment_rate"], ["interest rate", "unemployment rate"]], "dependent_var": ["house_price", "house price"], "forecast_period": [5]}}]}}}
{"id": "multiple_54", "category": "relevant_but_incorrect", "evaluation_entry": {"id": "multiple_54", "valid": false, "error": "invalid_param_value", "error_meta": {"param": "frequency", "actual_value": "quarterly", "expected_values": ["", "annually"], "decoded_output": [{"corporate_finance.dividend_data": {"years": 5, "company": "Apple Inc.", "frequency": "quarterly"}}], "possible_answer": {"corporate_finance.dividend_data": {"company": ["Apple Inc", "Apple", "Apple Inc."], "years": [5], "frequency": ["", "annually"]}}}}}
{"id": "multiple_55", "category": "relevant_but_incorrect", "evaluation_entry": {"id": "multiple_55", "valid": false, "error": "invalid_param_value", "error_meta": {"param": "company", "actual_value": "Alphabet Inc. (GOOGL)", "expected_values": ["Google", "GOOG"], "decoded_output": [{"stock_forecast": {"days": 3, "company": "Alphabet Inc. (GOOGL)", "model": "regression"}}], "possible_answer": {"stock_forecast": {"company": ["Google", "GOOG"], "days": [3], "model": ["", "regression"]}}}}}
{"id": "multiple_59", "category": "exactly_same_meaning", "evaluation_entry": {"id": "multiple_59", "valid": false, "error": "invalid_param_value", "error_meta": {"param": "specialization", "actual_value": ["Criminal law"], "expected_values": [["Criminal Law"], ["criminal law"]], "decoded_output": [{"lawyer_finder": {"experience": 1, "location": "New York, NY", "specialization": ["Criminal law"]}}], "possible_answer": {"lawyer_finder": {"location": ["New York", "New York, NY", "NY", "New York City", "NYC"], "specialization": [["Criminal Law"], ["criminal law"]], "experience": ["", 1]}}}}}
{"id": "multiple_61", "category": "exactly_same_meaning", "evaluation_entry": {"id": "multiple_61", "valid": false, "error": "invalid_param_value", "error_meta": {"param": "specialization", "actual_value": "small-space garden design", "expected_values": ["small space garden design"], "decoded_output": [{"landscape_architect.find_specialty": {"years_experience": 5, "location": "Portland, OR", "specialization": "small-space garden design"}}], "possible_answer": {"landscape_architect.find_specialty": {"location": ["Portland", "Portland, OR"], "specialization": ["small space garden design"], "years_experience": [5]}}}}}
{"id": "multiple_66", "category": "exactly_same_meaning", "evaluation_entry": {"id": "multiple_66", "valid": false, "error": "invalid_param_value", "error_meta": {"param": "start_location", "actual_value": "Las Vegas, NV", "expected_values": ["Las Vegas"], "decoded_output": [{"traffic_estimate": {"start_location": "Las Vegas, NV", "end_location": "Los Angeles, CA", "time_period": "weekend"}}], "possible_answer": {"traffic_estimate": {"start_location": ["Las Vegas"], "end_location": ["Los Angeles"], "time_period": ["weekend"]}}}}}
{"id": "multiple_68", "category": "exactly_same_meaning", "evaluation_entry": {"id": "multiple_68", "valid": false, "error": "invalid_param_value", "error_meta": {"param": "location", "actual_value": "New York Public Library", "expected_values": ["New York", "New York, NY", "New York City", "New York City, NY", "NYC", "New York public library"], "decoded_output": [{"library.search_books": {"title": "", "location": "New York Public Library", "genre": "historical fiction"}}], "possible_answer": {"library.search_books": {"location": ["New York", "New York, NY", "New York City", "New York City, NY", "NYC", "New York public library"], "genre": ["Historical Fiction", "historical fiction"], "title": [""]}}}}}
{"id": "multiple_74", "category": "exactly_same_meaning", "evaluation_entry": {"id": "multiple_74", "valid": false, "error": "invalid_param_value", "error_meta": {"param": "artist", "actual_value": "Vincent van Gogh (Vincent van Gogh)", "expected_values": ["Van Gogh"], "decoded_output": [{"art_auction.fetch_artwork_price": {"artwork_name": "Starry Night", "artist": "Vincent van Gogh (Vincent van Gogh)", "platform": "all"}}], "possible_answer": {"art_auction.fetch_artwork_price": {"artwork_name": ["Starry Night"], "artist": ["Van Gogh"], "platform": ["all", ""]}}}}}
{"id": "multiple_75", "category": "relevant_but_incorrect", "evaluation_entry": {"id": "multiple_75", "valid": false, "error": "invalid_param_value", "error_meta": {"param": "period", "actual_value": "Monthly", "expected_values": ["", "Daily"], "decoded_output": [{"paint_color.trends": {"room": "Living room", "period": "Monthly"}}], "possible_answer": {"paint_color.trends": {"room": ["living room", "Living room"], "period": ["", "Daily"]}}}}}
{"id": "multiple_79", "category": "exactly_same_meaning", "evaluation_entry": {"id": "multiple_79", "valid": false, "error": "invalid_param_value", "error_meta": {"param": "museum_name", "actual_value": "Museum of Modern Art (MoMA), New York", "expected_values": ["Museum of Modern Art", "MOMA", "Museum of Modern Art, New York"], "decoded_output": [{"exhibition_info": {"month": 1, "museum_name": "Museum of Modern Art (MoMA), New York"}}], "possible_answer": {"exhibition_info": {"museum_name": ["Museum of Modern Art", "MOMA", "Museum of Modern Art, New York"], "month": ["", 1]}}}}}
{"id": "multiple_86", "category": "relevant_but_incorrect", "evaluation_entry": {"id": "multiple_86", "valid": false, "error": "invalid_param_value", "error_meta": {"param": "difficulty", "actual_value": "intermediate", "expected_values": ["", "beginner"], "decoded_output": [{"BoardGameGeek.recommend": {"numPlayers": 2, "category": "strategy", "difficulty": "intermediate"}}], "possible_answer": {"BoardGameGeek.recommend": {"numPlayers": [2], "category": ["strategy"], "difficulty": ["", "beginner"]}}}}}
{"id": "multiple_89", "category": "exactly_same_meaning", "evaluation_entry": {"id": "multiple_89", "valid": false, "error": "invalid_param_value", "error_meta": {"param": "ingredients", "actual_value": ["chicken", "mushroom"], "expected_values": [["chicken", "mushrooms"], ["mushrooms", "chicken"]], "decoded_output": [{"recipe_search": {"calories": 500, "meal": "lunch", "ingredients": ["chicken", "mushroom"]}}], "possible_answer": {"recipe_search": {"ingredients": [["chicken", "mushrooms"], ["mushrooms", "chicken"]], "calories": [500], "meal": ["lunch", ""]}}}}}
{"id": "multiple_93", "category": "relevant_but_incorrect", "evaluation_entry": {"id": "multiple_93", "valid": false, "error": "invalid_param_value", "error_meta": {"param": "location", "actual_value": "New York Marriott Hotel", "expected_values": ["New York", "New York, NY", "NYC"], "decoded_output": [{"hotel.book": {"nights": 2, "location": "New York Marriott Hotel", "roomType": "Deluxe Room", "additional_services": ["breakfast"]}}], "possible_answer": {"hotel.book": {"location": ["New York", "New York, NY", "NYC"], "roomType": ["deluxe", "Deluxe"], "nights": [2], "additional_services": [["breakfast"]]}}}}}
{"id": "multiple_94", "category": "relevant_but_incorrect", "evaluation_entry": {"id": "multiple_94", "valid": false, "error": "invalid_param_value", "error_meta": {"param": "roomType", "actual_value": "Suite (large bed)", "expected_values": ["suite with queen size bed"], "decoded_output": [{"hotel_room_pricing.get": {"nights": 3, "hotelName": "Hilton New York", "roomType": "Suite (large bed)"}}], "possible_answer": {"hotel_room_pricing.get": {"hotelName": ["Hilton New York"], "roomType": ["suite with queen size bed"], "nights": [3]}}}}}
{"id": "multiple_99", "category": "relevant_but_incorrect", "evaluation_entry": {"id": "multiple_99", "valid": false, "error": "invalid_param_value", "error_meta": {"param": "function", "actual_value": "2*x^2", "expected_values": ["2x**2", "lambda x: 2x**2"], "decoded_output": [{"calculus.derivative": {"value": 1, "function": "2*x^2", "function_variable": "x"}}], "possible_answer": {"calculus.derivative": {"function": ["2x**2", "lambda x: 2x**2"], "value": [1], "function_variable": ["x", ""]}}}}}
{"id": "multiple_104", "category": "exactly_same_meaning", "evaluation_entry": {"id": "multiple_104", "valid": false, "error": "invalid_param_value", "error_meta": {"param": "origin", "actual_value": "New York City, NY", "expected_values": ["New York City", "NYC"], "decoded_output": [{"get_shortest_driving_distance": {"origin": "New York City, NY", "destination": "Washington, DC", "unit": "miles"}}], "possible_answer": {"get_shortest_driving_distance": {"origin": ["New York City", "NYC"], "destination": ["Washington D.C.", "D.C.", "DC"], "unit": ["", "kilometers"]}}}}}
{"id": "multiple_110", "category": "exactly_same_meaning", "evaluation_entry": {"id": "multiple_110", "valid": false, "error": "invalid_param_value", "error_meta": {"param": "species", "actual_value": "wise man", "expected_values": ["Homo sapiens", ""], "decoded_output": [{"mutation_type.find": {"snp_id": "rs6034464", "species": "wise man"}}], "possible_answer": {"mutation_type.find": {"snp_id": ["rs6034464"], "species": ["Homo sapiens", ""]}}}}}
{"id": "multiple_114", "category": "exactly_same_meaning", "evaluation_entry": {"id": "multiple_114", "valid": false, "error": "invalid_param_value", "error_meta": {"param": "species", "actual_value": "wise man", "expected_values": ["Homo Sapiens", "Homo sapiens"], "decoded_output": [{"prediction.evolution": {"years": 50, "species": "wise man", "model": "Darwin"}}], "possible_answer": {"prediction.evolution": {"species": ["Homo Sapiens", "Homo sapiens"], "years": [50], "model": ["Darwin", ""]}}}}}
{"id": "multiple_115", "category": "exactly_same_meaning", "evaluation_entry": {"id": "multiple_115", "valid": false, "error": "invalid_param_value", "error_meta": {"param": "location", "actual_value": "Manhattan, New York, NY", "expected_values": ["Manhattan"], "decoded_output": [{"find_restaurants": {"number": 5, "location": "Manhattan, New York, NY", "food_type": "Thai", "dietary_requirements": ["vegetarian"]}}], "possible_answer": {"find_restaurants": {"location": ["Manhattan"], "food_type": ["Thai"], "number": [5], "dietary_requirements": [["vegan"]]}}}}}
{"id": "multiple_119", "category": "exactly_same_meaning", "evaluation_entry": {"id": "multiple_119", "valid": false, "error": "invalid_param_value", "error_meta": {"param": "table", "actual_value": "User", "expected_values": ["user"], "decoded_output": [{"database.query": {"table": "User", "conditions": [{"field": "age", "operation": "", "value": "25"}, {"field": "Occupation", "operation": "=", "value": "Engineer"}]}}], "possible_answer": {"database.query": {"table": ["user"], "conditions": [[{"field": ["age"], "operation": [">"], "value": ["25"]}, {"field": ["job"], "operation": ["="], "value": ["engineer"]}]]}}}}}
{"id": "multiple_121", "category": "exactly_same_meaning", "evaluation_entry": {"id": "multiple_121", "valid": false, "error": "invalid_param_value", "error_meta": {"param": "unit", "actual_value": "square meter", "expected_values": ["", "square meters"], "decoded_output": [{"geometry.area_triangle": {"base": 6, "height": 10, "unit": "square meter"}}], "possible_answer": {"geometry.area_triangle": {"base": [6], "height": [10], "unit": ["", "square meters"]}}}}}
{"id": "multiple_122", "category": "exactly_same_meaning", "evaluation_entry": {"id": "multiple_122", "valid": false, "error": "invalid_param_value", "error_meta": {"param": "target", "actual_value": "Purchase amount", "expected_values": ["Purchase_Amount"], "decoded_output": [{"run_linear_regression": {"standardize": true, "target": "Purchase amount", "predictors": ["Age", "Income", "Level of education"]}}], "possible_answer": {"run_linear_regression": {"predictors": [["Age", "Income", "Education"], ["Age", "Education", "Income"], ["Income", "Age", "Education"], ["Income", "Education", "Age"], ["Education", "Age", "Income"], ["Education", "Income", "Age"]], "target": ["Purchase_Amount"], "standardize": [true]}}}}}
{"id": "multiple_124", "category": "relevant_but_incorrect", "evaluation_entry": {"id": "multiple_124", "valid": false, "error": "invalid_param_value", "error_meta": {"param": "round", "actual_value": 4, "expected_values": ["", 2], "decoded_output": [{"probabilities.calculate_single": {"total_outcomes": 52, "event_outcomes": 4, "round": 4}}], "possible_answer": {"probabilities.calculate_single": {"total_outcomes": [52], "event_outcomes": [4], "round": ["", 2]}}}}}
{"id": "multiple_136", "category": "exactly_same_meaning", "evaluation_entry": {"id": "multiple_136", "valid": false, "error": "invalid_param_value", "error_meta": {"param": "type", "actual_value": "violent crime", "expected_values": ["violent", "Violent"], "decoded_output": [{"get_crime_rate": {"year": 2020, "city": "San Francisco", "state": "California", "type": "violent crime"}}], "possible_answer": {"get_crime_rate": {"city": ["San Francisco", "San Francisco, CA", "SF"], "state": ["California", "CA"], "type": ["violent", "Violent"], "year": [2020]}}}}}
{"id": "multiple_138", "category": "exactly_same_meaning", "evaluation_entry": {"id": "multiple_138", "valid": false, "error": "invalid_param_value", "error_meta": {"param": "case_id", "actual_value": "R v Adams", "expected_values": ["R vs Adams", "R_vs_Adams"], "decoded_output": [{"legal_case.fetch": {"details": true, "case_id": "R v Adams"}}], "possible_answer": {"legal_case.fetch": {"case_id": ["R vs Adams", "R_vs_Adams"], "details": [true]}}}}}
{"id": "multiple_139", "category": "relevant_but_incorrect", "evaluation_entry": {"id": "multiple_139", "valid": false, "error": "invalid_param_value", "error_meta": {"param": "case_type", "actual_value": "all", "expected_values": ["Patent"], "decoded_output": [{"lawsuit_details.find": {"year": 2010, "company_name": "Apple Inc.", "case_type": "all"}}], "possible_answer": {"lawsuit_details.find": {"company_name": ["Apple Inc."], "year": [2010], "case_type": ["Patent"]}}}}}
{"id": "multiple_142", "category": "exactly_same_meaning", "evaluation_entry": {"id": "multiple_142", "valid": false, "error": "invalid_param_value", "error_meta": {"param": "location", "actual_value": "Miami, Florida, USA", "expected_values": ["Miami", "Miami, Florida", "FL"], "decoded_output": [{"weather.humidity_forecast": {"days": 7, "min_humidity": 0, "location": "Miami, Florida, USA"}}], "possible_answer": {"weather.humidity_forecast": {"location": ["Miami", "Miami, Florida", "FL"], "days": [7], "min_humidity": ["", 0]}}}}}
{"id": "multiple_147", "category": "exactly_same_meaning", "evaluation_entry": {"id": "multiple_147", "valid": false, "error": "invalid_param_value", "error_meta": {"param": "end", "actual_value": "Los Angeles, CA", "expected_values": ["Los Angeles", "LA"], "decoded_output": [{"map_service.get_directions": {"start": "New York, NY", "end": "Los Angeles, CA", "avoid": ["highways", "tolls"]}}], "possible_answer": {"map_service.get_directions": {"start": ["New York", "New York, NY", "NYC"], "end": ["Los Angeles", "LA"], "avoid": [["highways", "tolls"], ["tolls", "highways"]]}}}}}
{"id": "multiple_149", "category": "exactly_same_meaning", "evaluation_entry": {"id": "multiple_149", "valid": false, "error": "invalid_param_value", "error_meta": {"param": "language", "actual_value": "en", "expected_values": ["english", "English"], "decoded_output": [{"sentiment_analysis": {"text": "I love the food here! It's always fresh and delicious.", "language": "en"}}], "possible_answer": {"sentiment_analysis": {"text": ["I love the food here! It's always fresh and delicious."], "language": ["english", "English"]}}}}}
{"id": "multiple_151", "category": "exactly_same_meaning", "evaluation_entry": {"id": "multiple_151", "valid": false, "error": "invalid_param_value", "error_meta": {"param": "sub_topics", "actual_value": ["behavior", "group dynamics"], "expected_values": [["behaviour", "group dynamics"], ["group dynamics", "behaviour"]], "decoded_output": [{"social_media_analytics.most_followed": {"topic": "psychology", "region": "global", "sub_topics": ["behavior", "group dynamics"]}}], "possible_answer": {"social_media_analytics.most_followed": {"topic": ["psychology", "Psychology"], "sub_topics": [["behaviour", "group dynamics"], ["group dynamics", "behaviour"]], "region": ["", "global"]}}}}}
{"id": "multiple_156", "category": "wrong_values", "evaluation_entry": {"id": "multiple_156", "valid": false, "error": "invalid_param_value", "error_meta": {"param": "category", "actual_value": "Physics", "expected_values": ["", "all"], "decoded_output": [{"historical_contrib.get_contrib": {"scientist": "Albert Einstein", "date": "1915-03-17", "category": "Physics"}}], "possible_answer": {"historical_contrib.get_contrib": {"scientist": ["Albert Einstein"], "date": ["1915-03-17", "03/17/1915", "Mar.17,1915"], "category": ["", "all"]}}}}}
{"id": "multiple_161", "category": "exactly_same_meaning", "evaluation_entry": {"id": "multiple_161", "valid": false, "error": "invalid_param_value", "error_meta": {"param": "month", "actual_value": "January 2026", "expected_values": ["upcoming", "next month", "upcoming month", "next", ""], "decoded_output": [{"find_exhibition": {"location": "New York, NY", "art_form": "sculpture", "month": "January 2026", "user_ratings": "high"}}], "possible_answer": {"find_exhibition": {"location": ["New York", "New York, NY", "New York City", "NYC", "NY"], "art_form": ["sculpture", "modern sculpture"], "month": ["upcoming", "next month", "upcoming month", "next", ""], "user_ratings": ["high", ""]}}}}}
{"id": "multiple_164", "category": "relevant_but_incorrect", "evaluation_entry": {"id": "multiple_164", "valid": false, "error": "invalid_param_value", "error_meta": {"param": "finish", "actual_value": "Rosewood veneer", "expected_values": ["Rosewood"], "decoded_output": [{"instrument_price.get": {"brand": "Fender", "model": "American Professional II Stratocaster", "finish": "Rosewood veneer"}}], "possible_answer": {"instrument_price.get": {"brand": ["Fender"], "model": ["American Professional II Stratocaster"], "finish": ["Rosewood"]}}}}}
{"id": "multiple_171", "category": "exactly_same_meaning", "evaluation_entry": {"id": "multiple_171", "valid": false, "error": "invalid_param_value", "error_meta": {"param": "teams", "actual_value": ["Los Angeles Lakers", "Los Angeles Clippers"], "expected_values": [["Lakers", "Clippers"], ["Clippers", "Lakers"]], "decoded_output": [{"game_result.get_winner": {"venue": "", "date": "2021-01-28", "teams": ["Los Angeles Lakers", "Los Angeles Clippers"]}}], "possible_answer": {"game_result.get_winner": {"teams": [["Lakers", "Clippers"], ["Clippers", "Lakers"]], "date": ["2021-01-28", "01/28/2021", "Jan.28,2021"], "venue": [""]}}}}}
{"id": "multiple_172", "category": "exactly_same_meaning", "evaluation_entry": {"id": "multiple_172", "valid": false, "error": "invalid_param_value", "error_meta": {"param": "name", "actual_value": "LeBron James", "expected_values": ["Lebron James"], "decoded_output": [{"sports_db.find_athlete": {"team": "", "name": "LeBron James", "sport": "Basketball"}}], "possible_answer": {"sports_db.find_athlete": {"name": ["Lebron James"], "sport": ["Basketball"], "team": [""]}}}}}
{"id": "multiple_173", "category": "wrong_values", "evaluation_entry": {"id": "multiple_173", "valid": false, "error": "invalid_param_value", "error_meta": {"param": "top", "actual_value": 30, "expected_values": [1, ""], "decoded_output": [{"get_defense_ranking": {"season": 2021, "top": 30}}], "possible_answer": {"get_defense_ranking": {"season": [2021], "top": [1, ""]}}}}}
{"id": "multiple_177", "category": "exactly_same_meaning", "evaluation_entry": {"id": "multiple_177", "valid": false, "error": "invalid_param_value", "error_meta": {"param": "location", "actual_value": "New York City", "expected_values": ["New York", "New York, NY", "NYC"], "decoded_output": [{"board_game.chess.get_top_players": {"minimum_rating": 2300, "number_of_players": 10, "location": "New York City"}}], "possible_answer": {"board_game.chess.get_top_players": {"location": ["New York", "New York, NY", "NYC"], "minimum_rating": [2300], "number_of_players": ["", 10]}}}}}
{"id": "multiple_178", "category": "wrong_values", "evaluation_entry": {"id": "multiple_178", "valid": false, "error": "invalid_param_value", "error_meta": {"param": "deck", "actual_value": [], "expected_values": [""], "decoded_output": [{"find_card_in_deck": {"rank": "Queen", "suit": "Hearts", "deck": []}}], "possible_answer": {"find_card_in_deck": {"rank": ["Queen"], "suit": ["Hearts"], "deck": [""]}}}}}
{"id": "multiple_182", "category": "misc_errors", "evaluation_entry": {"id": "multiple_182", "valid": false, "error": "invalid_entry_count", "error_meta": {"entry_count": 5, "decoded_output": [{"multiplayer_game_finder": {"rating": 4.6, "platform": "Windows 10", "genre": "Action"}}, {"multiplayer_game_finder": {"rating": 4.6, "platform": "Windows 10", "genre": "Adventure"}}, {"multiplayer_game_finder": {"rating": 4.6, "platform": "Windows 10", "genre": "Racing"}}, {"multiplayer_game_finder": {"rating": 4.6, "platform": "Windows 10", "genre": "Strategy"}}, {"multiplayer_game_finder": {"rating": 4.6, "platform": "Windows 10", "genre": "Simulation"}}], "possible_answer": [{"multiplayer_game_finder": {"platform": ["Windows 10"], "rating": [4.5], "genre": [""]}}]}}}
{"id": "multiple_184", "category": "relevant_but_incorrect", "evaluation_entry": {"id": "multiple_184", "valid": false, "error": "invalid_param_value", "error_meta": {"param": "ingredients", "actual_value": ["pasta", "cheese", "olive oil", "garlic", "onion", "cream", "butter", "salt", "pepper", "basil"], "expected_values": [["pasta", "cheese"], ["cheese", "pasta"]], "decoded_output": [{"recipe_search": {"servings": 2, "dietary_restriction": "Vegetarian", "ingredients": ["pasta", "cheese", "olive oil", "garlic", "onion", "cream", "butter", "salt", "pepper", "basil"]}}], "possible_answer": {"recipe_search": {"dietary_restriction": ["Vegetarian"], "ingredients": [["pasta", "cheese"], ["cheese", "pasta"]], "servings": [2]}}}}}
{"id": "multiple_185", "category": "relevant_but_incorrect", "evaluation_entry": {"id": "multiple_185", "valid": false, "error": "invalid_param_value", "error_meta": {"param": "amenities", "actual_value": ["Courtyard"], "expected_values": [["Patio"]], "decoded_output": [{"restaurant_search.find_closest": {"location": "Boston, MA", "cuisine": "Sushi", "amenities": ["Courtyard"]}}], "possible_answer": {"restaurant_search.find_closest": {"location": ["Boston", "Boston, MA"], "cuisine": ["Sushi"], "amenities": [["Patio"]]}}}}}
{"id": "multiple_186", "category": "relevant_but_incorrect", "evaluation_entry": {"id": "multiple_186", "valid": false, "error": "invalid_param_value", "error_meta": {"param": "dietary_restrictions", "actual_value": "vegetarian", "expected_values": ["vegan"], "decoded_output": [{"find_recipe": {"time": 30, "dietary_restrictions": "vegetarian", "recipe_type": "brownie"}}], "possible_answer": {"find_recipe": {"dietary_restrictions": ["vegan"], "recipe_type": ["dessert"], "time": [30]}}}}}
{"id": "multiple_187", "category": "relevant_but_incorrect", "evaluation_entry": {"id": "multiple_187", "valid": false, "error": "invalid_param_value", "error_meta": {"param": "location", "actual_value": "The Angels", "expected_values": ["Los Angeles", "LA"], "decoded_output": [{"whole_foods.check_price": {"location": "The Angels", "items": ["tomatoes", "lettuce"]}}], "possible_answer": {"whole_foods.check_price": {"location": ["Los Angeles", "LA"], "items": [["tomatoes", "lettuce"], ["lettuce", "tomatoes"]]}}}}}
{"id": "multiple_190", "category": "relevant_but_incorrect", "evaluation_entry": {"id": "multiple_190", "valid": false, "error": "invalid_param_value", "error_meta": {"param": "hotel_name", "actual_value": "Hilton Chicago", "expected_values": ["Hilton Hotel", "Hilton"], "decoded_output": [{"book_hotel": {"nights": 2, "hotel_name": "Hilton Chicago", "location": "Chicago", "room_type": "single room", "start_date": "2022-12-10"}}], "possible_answer": {"book_hotel": {"hotel_name": ["Hilton Hotel", "Hilton"], "location": ["Chicago"], "room_type": ["single", "Single"], "start_date": ["2022-12-10", "10/12/2022", "Dec.10,2022", "10th December 2022", "10 December 2022"], "nights": [2]}}}}}
{"id": "multiple_191", "category": "relevant_but_incorrect", "evaluation_entry": {"id": "multiple_191", "valid": false, "error": "invalid_param_value", "error_meta": {"param": "hotel_name", "actual_value": "Paradise Hotel Las Vegas", "expected_values": ["Hotel Paradise"], "decoded_output": [{"book_hotel": {"stay_duration": 3, "hotel_name": "Paradise Hotel Las Vegas", "location": "Las Vegas, NV", "room_type": "Deluxe room", "start_date": "05-12-2022", "view": "City view"}}], "possible_answer": {"book_hotel": {"hotel_name": ["Hotel Paradise"], "location": ["Las Vegas", "Las Vegas, NV", "LV"], "room_type": ["luxury", "Luxury"], "start_date": ["05-12-2022", "2022-05-12", "12/05/2022", "May.12,2022", "May 12, 2022"], "stay_duration": [3], "view": ["city", "city view"]}}}}}
{"id": "multiple_193", "category": "exactly_same_meaning", "evaluation_entry": {"id": "multiple_193", "valid": false, "error": "invalid_param_value", "error_meta": {"param": "start_location", "actual_value": "Eiffel Tower, Paris, France", "expected_values": ["Eiffel Tower"], "decoded_output": [{"maps.get_distance_duration": {"traffic": false, "start_location": "Eiffel Tower, Paris, France", "end_location": "Louvre Museum, Paris, France"}}], "possible_answer": {"maps.get_distance_duration": {"start_location": ["Eiffel Tower"], "end_location": ["Louvre Museum"], "traffic": ["", false]}}}}}
{"id": "multiple_194", "category": "exactly_same_meaning", "evaluation_entry": {"id": "multiple_194", "valid": false, "error": "invalid_param_value", "error_meta": {"param": "museum_name", "actual_value": "The Metropolitan Museum of Art", "expected_values": ["Metropolitan Museum of Art", "The Met", "Met Museum"], "decoded_output": [{"get_museum_hours": {"museum_name": "The Metropolitan Museum of Art", "day": "Saturday"}}], "possible_answer": {"get_museum_hours": {"museum_name": ["Metropolitan Museum of Art", "The Met", "Met Museum"], "day": ["Saturday"]}}}}}
{"id": "multiple_197", "category": "exactly_same_meaning", "evaluation_entry": {"id": "multiple_197", "valid": false, "error": "invalid_param_value", "error_meta": {"param": "species", "actual_value": "wise man", "expected_values": ["", "Homo sapiens"], "decoded_output": [{"mutation_type.find": {"snp_id": "rs6034464", "species": "wise man"}}], "possible_answer": {"mutation_type.find": {"snp_id": ["rs6034464"], "species": ["", "Homo sapiens"]}}}}}
{"id": "multiple_199", "category": "exactly_same_meaning", "evaluation_entry": {"id": "multiple_199", "valid": false, "error": "invalid_param_value", "error_meta": {"param": "location", "actual_value": "Yellowstone National Park", "expected_values": ["Yellowstone", "yellowstone"], "decoded_output": [{"forest_growth_forecast": {"years": 5, "include_human_impact": true, "location": "Yellowstone National Park"}}], "possible_answer": {"forest_growth_forecast": {"location": ["Yellowstone", "yellowstone"], "years": [5], "include_human_impact": [true]}}}}}
